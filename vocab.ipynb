{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "not_found_words = set()\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('read', 'NN'), ('fell', 'VBD'), ('love', 'VB'), ('way', 'NN'), ('fall', 'NN'), ('asleep', 'VBP'), ('slowly', 'RB')]\n",
      "word:  read | root : read\n",
      "word:  fell | root : fell\n",
      "word:  love | root : love\n",
      "word:  way | root : way\n",
      "word:  fall | root : fall\n",
      "word:  asleep | root : asleep\n",
      "word:  slowly | root : slowly\n",
      "[('loved', 'VBN'), ('yesterday', 'NN'), ('love', 'VB'), ('still', 'RB'), ('always', 'RB'), ('always', 'RB')]\n",
      "word:  loved | root : love\n",
      "word:  yesterday | root : yesterday\n",
      "word:  love | root : love\n",
      "word:  still | root : still\n",
      "word:  always | root : always\n",
      "word:  always | root : always\n",
      "[('saw', 'NN'), ('perfect', 'NN'), ('loved', 'VBD'), ('saw', 'JJ'), ('perfect', 'NN'), ('loved', 'VBD'), ('even', 'RB')]\n",
      "word:  saw | root : saw\n",
      "word:  perfect | root : perfect\n",
      "word:  loved | root : love\n",
      "word:  saw | root : saw\n",
      "word:  perfect | root : perfect\n",
      "word:  loved | root : love\n",
      "word:  even | root : even\n",
      "[('love', 'NN'), ('love', 'NN'), ('made', 'VBD'), ('making', 'VBG'), ('love', 'VB'), ('part', 'NN'), ('bring', 'NN')]\n",
      "word:  love | root : love\n",
      "word:  love | root : love\n",
      "word:  made | root : make\n",
      "word:  making | root : make\n",
      "word:  love | root : love\n",
      "word:  part | root : part\n",
      "word:  bring | root : bring\n",
      "[('thinking', 'VBG'), ('keeps', 'NNS'), ('awake', 'VBP'), ('dreaming', 'VBG'), ('keeps', 'NNS'), ('asleep', 'JJ'), ('keeps', 'NNS'), ('alive', 'JJ')]\n",
      "word:  thinking | root : think\n",
      "word:  keeps | root : keep\n",
      "word:  awake | root : awake\n",
      "word:  dreaming | root : dream\n",
      "word:  keeps | root : keep\n",
      "word:  asleep | root : asleep\n",
      "word:  keeps | root : keep\n",
      "word:  alive | root : alive\n",
      "[('need', 'NN'), ('like', 'IN'), ('heart', 'NN'), ('needs', 'VBZ'), ('beat', 'NN')]\n",
      "word:  need | root : need\n",
      "('like', 'IN')  not found\n",
      "word:  heart | root : heart\n",
      "word:  needs | root : need\n",
      "word:  beat | root : beat\n",
      "[('say', 'VB'), ('love', 'NN'), ('mean', 'NN'), ('love', 'VBP'), ('love', 'NN'), ('mean', 'NN'), ('love', 'IN'), ('bad', 'JJ'), ('days', 'NNS'), ('ahead', 'RB'), ('us', 'PRP'), ('love', 'VB'), ('fight', 'NN'), ('ever', 'RB'), ('love', 'VB'), ('distance', 'NN'), ('us', 'PRP'), ('love', 'VBP'), ('obstacle', 'NN'), ('could', 'MD'), ('try', 'VB'), ('come', 'VB'), ('us', 'PRP'), ('love', 'VB')]\n",
      "word:  say | root : say\n",
      "word:  love | root : love\n",
      "word:  mean | root : mean\n",
      "word:  love | root : love\n",
      "word:  love | root : love\n",
      "word:  mean | root : mean\n",
      "('love', 'IN')  not found\n",
      "word:  bad | root : bad\n",
      "word:  days | root : day\n",
      "word:  ahead | root : ahead\n",
      "('us', 'PRP')  not found\n",
      "word:  love | root : love\n",
      "word:  fight | root : fight\n",
      "word:  ever | root : ever\n",
      "word:  love | root : love\n",
      "word:  distance | root : distance\n",
      "('us', 'PRP')  not found\n",
      "word:  love | root : love\n",
      "word:  obstacle | root : obstacle\n",
      "('could', 'MD')  not found\n",
      "word:  try | root : try\n",
      "word:  come | root : come\n",
      "('us', 'PRP')  not found\n",
      "word:  love | root : love\n",
      "[('know', 'NNS'), ('love', 'VBP')]\n",
      "word:  know | root : know\n",
      "word:  love | root : love\n",
      "[('swear', 'JJ'), ('love', 'NN'), ('right', 'RB'), ('yet', 'RB'), ('know', 'VBP'), ('tomorrow', 'NN')]\n",
      "word:  swear | root : swear\n",
      "word:  love | root : love\n",
      "word:  right | root : right\n",
      "word:  yet | root : yet\n",
      "word:  know | root : know\n",
      "word:  tomorrow | root : tomorrow\n",
      "[('live', 'JJ'), ('hundred', 'VBD'), ('want', 'JJ'), ('live', 'JJ'), ('hundred', 'VBD'), ('minus', 'CC'), ('one', 'CD'), ('day', 'NN'), ('never', 'RB'), ('live', 'VBP'), ('without', 'IN')]\n",
      "word:  live | root : live\n",
      "word:  hundred | root : hundred\n",
      "word:  want | root : want\n",
      "word:  live | root : live\n",
      "word:  hundred | root : hundred\n",
      "('minus', 'CC')  not found\n",
      "('one', 'CD')  not found\n",
      "word:  day | root : day\n",
      "word:  never | root : never\n",
      "word:  live | root : live\n",
      "('without', 'IN')  not found\n",
      "[('today', 'NN'), ('truer', 'VBZ'), ('true', 'JJ'), ('one', 'CD'), ('alive', 'JJ'), ('youer', 'NN')]\n",
      "word:  today | root : today\n",
      "word:  truer | root : truer\n",
      "word:  true | root : true\n",
      "('one', 'CD')  not found\n",
      "word:  alive | root : alive\n",
      "word:  youer | root : youer\n",
      "[('know', 'JJ'), ('world', 'NN'), ('going', 'VBG'), ('crazy', 'JJ'), ('best', 'JJS'), ('rapper', 'JJ'), ('white', 'JJ'), ('guy', 'NN'), ('best', 'JJS'), ('golfer', 'NN'), ('black', 'JJ'), ('guy', 'NN'), ('tallest', 'JJS'), ('guy', 'NN'), ('nba', 'IN'), ('chinese', 'JJ'), ('swiss', 'JJ'), ('hold', 'NN'), ('america', 'JJ'), ('cup', 'NN'), ('france', 'NN'), ('accusing', 'VBG'), ('u', 'JJ'), ('arrogance', 'NN'), ('germany', 'NN'), ('want', 'VBP'), ('go', 'VB'), ('war', 'NN'), ('three', 'CD'), ('powerful', 'JJ'), ('men', 'NNS'), ('america', 'VBP'), ('named', 'VBN'), ('bush', 'NN'), ('dick', 'NN'), ('colin', 'NN'), ('need', 'VBP'), ('say', 'VBP')]\n",
      "word:  know | root : know\n",
      "word:  world | root : world\n",
      "word:  going | root : go\n",
      "word:  crazy | root : crazy\n",
      "word:  best | root : best\n",
      "word:  rapper | root : rapper\n",
      "word:  white | root : white\n",
      "word:  guy | root : guy\n",
      "word:  best | root : best\n",
      "word:  golfer | root : golfer\n",
      "word:  black | root : black\n",
      "word:  guy | root : guy\n",
      "word:  tallest | root : tall\n",
      "word:  guy | root : guy\n",
      "('nba', 'IN')  not found\n",
      "word:  chinese | root : chinese\n",
      "word:  swiss | root : swiss\n",
      "word:  hold | root : hold\n",
      "word:  america | root : america\n",
      "word:  cup | root : cup\n",
      "word:  france | root : france\n",
      "word:  accusing | root : accuse\n",
      "word:  u | root : u\n",
      "word:  arrogance | root : arrogance\n",
      "word:  germany | root : germany\n",
      "word:  want | root : want\n",
      "word:  go | root : go\n",
      "word:  war | root : war\n",
      "('three', 'CD')  not found\n",
      "word:  powerful | root : powerful\n",
      "word:  men | root : men\n",
      "word:  america | root : america\n",
      "word:  named | root : name\n",
      "word:  bush | root : bush\n",
      "word:  dick | root : dick\n",
      "word:  colin | root : colin\n",
      "word:  need | root : need\n",
      "word:  say | root : say\n",
      "[('believe', 'VB'), ('nothing', 'NN'), ('hear', 'JJ'), ('one', 'CD'), ('half', 'NN'), ('see', 'NN')]\n",
      "word:  believe | root : believe\n",
      "word:  nothing | root : nothing\n",
      "word:  hear | root : hear\n",
      "('one', 'CD')  not found\n",
      "word:  half | root : half\n",
      "word:  see | root : see\n",
      "[('lord', 'NN'), ('fools', 'VBZ'), ('mortals', 'NNS')]\n",
      "word:  lord | root : lord\n",
      "word:  fools | root : fool\n",
      "word:  mortals | root : mortal\n",
      "[('world', 'NN'), ('tragedy', 'NN'), ('feel', 'VBP'), ('comedy', 'NN'), ('think', 'VBP')]\n",
      "word:  world | root : world\n",
      "word:  tragedy | root : tragedy\n",
      "word:  feel | root : feel\n",
      "word:  comedy | root : comedy\n",
      "word:  think | root : think\n",
      "[('life', 'NN'), ('comedy', 'NN'), ('think', 'VBP'), ('tragedy', 'NN'), ('feel', 'NN')]\n",
      "word:  life | root : life\n",
      "word:  comedy | root : comedy\n",
      "word:  think | root : think\n",
      "word:  tragedy | root : tragedy\n",
      "word:  feel | root : feel\n",
      "[('thin', 'JJ'), ('line', 'NN'), ('separates', 'NNS'), ('laughter', 'RBR'), ('pain', 'VBP'), ('comedy', 'JJ'), ('tragedy', 'NN'), ('humor', 'NN'), ('hurt', 'VBD')]\n",
      "word:  thin | root : thin\n",
      "word:  line | root : line\n",
      "word:  separates | root : separate\n",
      "word:  laughter | root : laughter\n",
      "word:  pain | root : pain\n",
      "word:  comedy | root : comedy\n",
      "word:  tragedy | root : tragedy\n",
      "word:  humor | root : humor\n",
      "word:  hurt | root : hurt\n",
      "[('self', 'NN'), ('important', 'JJ'), ('everybody', 'NN'), ('going', 'VBG'), ('save', 'JJ'), ('something', 'NN'), ('save', 'VB'), ('trees', 'NNS'), ('save', 'VBP'), ('bees', 'NNS'), ('save', 'VBP'), ('whales', 'NNS'), ('save', 'VBP'), ('snails', 'NNS')]\n",
      "word:  self | root : self\n",
      "word:  important | root : important\n",
      "word:  everybody | root : everybody\n",
      "word:  going | root : go\n",
      "word:  save | root : save\n",
      "word:  something | root : something\n",
      "word:  save | root : save\n",
      "word:  trees | root : tree\n",
      "word:  save | root : save\n",
      "word:  bees | root : bee\n",
      "word:  save | root : save\n",
      "word:  whales | root : whale\n",
      "word:  save | root : save\n",
      "word:  snails | root : snail\n",
      "[]\n",
      "[('thankfully', 'RB'), ('persistence', 'NN'), ('great', 'JJ'), ('substitute', 'NN'), ('talent', 'NN')]\n",
      "word:  thankfully | root : thankfully\n",
      "word:  persistence | root : persistence\n",
      "word:  great | root : great\n",
      "word:  substitute | root : substitute\n",
      "word:  talent | root : talent\n",
      "[('lot', 'NN'), ('cared', 'VBD'), ('enough', 'RB')]\n",
      "word:  lot | root : lot\n",
      "word:  cared | root : care\n",
      "word:  enough | root : enough\n",
      "[('two', 'CD'), ('tragedies', 'NNS'), ('life', 'NN'), ('one', 'CD'), ('lose', 'JJ'), ('heart', 'NN'), ('desire', 'NN'), ('gain', 'NN')]\n",
      "('two', 'CD')  not found\n",
      "word:  tragedies | root : tragedy\n",
      "word:  life | root : life\n",
      "('one', 'CD')  not found\n",
      "word:  lose | root : lose\n",
      "word:  heart | root : heart\n",
      "word:  desire | root : desire\n",
      "word:  gain | root : gain\n",
      "[('world', 'NN'), ('tragedy', 'NN'), ('feel', 'VBP'), ('comedy', 'NN'), ('think', 'VBP')]\n",
      "word:  world | root : world\n",
      "word:  tragedy | root : tragedy\n",
      "word:  feel | root : feel\n",
      "word:  comedy | root : comedy\n",
      "word:  think | root : think\n",
      "[('never', 'RB'), ('story', 'NN'), ('woe', 'NN'), ('juliet', 'JJ'), ('romeo', 'NN')]\n",
      "word:  never | root : never\n",
      "word:  story | root : story\n",
      "word:  woe | root : woe\n",
      "word:  juliet | root : juliet\n",
      "word:  romeo | root : romeo\n",
      "[('life', 'NN'), ('comedy', 'NN'), ('think', 'VBP'), ('tragedy', 'NN'), ('feel', 'NN')]\n",
      "word:  life | root : life\n",
      "word:  comedy | root : comedy\n",
      "word:  think | root : think\n",
      "word:  tragedy | root : tragedy\n",
      "word:  feel | root : feel\n",
      "[('weeping', 'VBG'), ('thing', 'NN'), ('crying', 'VBG'), ('takes', 'VBZ'), ('whole', 'JJ'), ('body', 'NN'), ('weep', 'JJ'), ('feel', 'NN'), ('like', 'IN'), ('bones', 'NNS'), ('left', 'VBD'), ('hold', 'NN')]\n",
      "word:  weeping | root : weep\n",
      "word:  thing | root : thing\n",
      "word:  crying | root : cry\n",
      "word:  takes | root : take\n",
      "word:  whole | root : whole\n",
      "word:  body | root : body\n",
      "word:  weep | root : weep\n",
      "word:  feel | root : feel\n",
      "('like', 'IN')  not found\n",
      "word:  bones | root : bone\n",
      "word:  left | root : leave\n",
      "word:  hold | root : hold\n",
      "[('thin', 'JJ'), ('line', 'NN'), ('separates', 'NNS'), ('laughter', 'RBR'), ('pain', 'VBP'), ('comedy', 'JJ'), ('tragedy', 'NN'), ('humor', 'NN'), ('hurt', 'VBD')]\n",
      "word:  thin | root : thin\n",
      "word:  line | root : line\n",
      "word:  separates | root : separate\n",
      "word:  laughter | root : laughter\n",
      "word:  pain | root : pain\n",
      "word:  comedy | root : comedy\n",
      "word:  tragedy | root : tragedy\n",
      "word:  humor | root : humor\n",
      "word:  hurt | root : hurt\n",
      "[('single', 'JJ'), ('death', 'NN'), ('tragedy', 'NN'), ('million', 'CD'), ('deaths', 'NNS'), ('statistic', 'JJ')]\n",
      "word:  single | root : single\n",
      "word:  death | root : death\n",
      "word:  tragedy | root : tragedy\n",
      "('million', 'CD')  not found\n",
      "word:  deaths | root : death\n",
      "word:  statistic | root : statistic\n",
      "[('go', 'VB'), ('go', 'VB')]\n",
      "word:  go | root : go\n",
      "word:  go | root : go\n",
      "[('irish', 'JJ'), ('abiding', 'VBG'), ('sense', 'NN'), ('tragedy', 'NN'), ('sustained', 'VBD'), ('temporary', 'JJ'), ('periods', 'NNS'), ('joy', 'NN')]\n",
      "word:  irish | root : irish\n",
      "word:  abiding | root : abide\n",
      "word:  sense | root : sense\n",
      "word:  tragedy | root : tragedy\n",
      "word:  sustained | root : sustain\n",
      "word:  temporary | root : temporary\n",
      "word:  periods | root : period\n",
      "word:  joy | root : joy\n"
     ]
    }
   ],
   "source": [
    "def addToVocab(filename):\n",
    "    global counter\n",
    "    f = open(filename,\"r\")\n",
    "    for line in f:\n",
    "        line = line.lower()\n",
    "        sent = re.sub('[\\W_]+', ' ', line)\n",
    "        wordsList = nltk.word_tokenize(sent)\n",
    "        wordsList = [w for w in wordsList if not w in stop_words]\n",
    "        tagged = nltk.pos_tag(wordsList)\n",
    "        print(tagged)\n",
    "        for word in tagged:\n",
    "            try:\n",
    "                tag = get_wordnet_pos(word[1])\n",
    "                if tag != None :\n",
    "                    final_word =  lemmatizer.lemmatize(word[0], pos = tag )\n",
    "                    print(\"word: \", word[0], \"| root :\",final_word)\n",
    "                    vocab.add( final_word)\n",
    "                else:\n",
    "                    print(word, \" not found\")\n",
    "                    not_found_words.add(word)\n",
    "                    counter +=1\n",
    "            except:\n",
    "                print(word, \" not found\")\n",
    "                not_found_words.add(word)\n",
    "                counter +=1\n",
    "        # print(tagged)\n",
    "    f.close()\n",
    "\n",
    "addToVocab(\"love-quotes.txt\")\n",
    "addToVocab(\"comedy-quotes.txt\")\n",
    "addToVocab(\"tragedy-quotes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('could', 'MD'), ('one', 'CD'), ('love', 'IN'), ('without', 'IN'), ('minus', 'CC'), ('nba', 'IN'), ('million', 'CD'), ('like', 'IN'), ('two', 'CD'), ('us', 'PRP'), ('three', 'CD')}\n",
      "136\n",
      "17\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "print(not_found_words)\n",
    "print(len(vocab))\n",
    "print(counter)\n",
    "print(len(not_found_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test and add field\n",
    "\"us\" in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('warrior')\n",
    "vocab.add('abuse')\n",
    "vocab.add('vile')\n",
    "vocab.add('hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "{'body', 'ever', 'hate', 'something', 'woe', 'fell', 'need', 'right', 'humor', 'whole', 'abuse', 'bee', 'truer', 'want', 'never', 'swiss', 'yet', 'think', 'go', 'war', 'save', 'warrior', 'white', 'abide', 'keep', 'guy', 'dick', 'read', 'comedy', 'hear', 'pain', 'powerful', 'weep', 'half', 'chinese', 'everybody', 'gain', 'world', 'accuse', 'distance', 'tragedy', 'fool', 'cry', 'hold', 'obstacle', 'swear', 'thankfully', 'beat', 'statistic', 'leave', 'lot', 'say', 'men', 'fall', 'single', 'black', 'lose', 'romeo', 'joy', 'saw', 'laughter', 'know', 'sustain', 'tall', 'self', 'always', 'talent', 'hurt', 'persistence', 'enough', 'juliet', 'important', 'try', 'france', 'name', 'even', 'period', 'snail', 'thin', 'true', 'rapper', 'arrogance', 'bush', 'temporary', 'day', 'whale', 'crazy', 'see', 'separate', 'bad', 'still', 'live', 'awake', 'vile', 'alive', 'life', 'take', 'fight', 'thing', 'yesterday', 'sense', 'heart', 'best', 'desire', 'line', 'feel', 'america', 'way', 'tree', 'colin', 'ahead', 'substitute', 'story', 'cup', 'great', 'youer', 'u', 'come', 'slowly', 'make', 'part', 'bring', 'nothing', 'believe', 'bone', 'perfect', 'dream', 'hundred', 'today', 'mortal', 'asleep', 'irish', 'lord', 'love', 'tomorrow', 'care', 'germany', 'mean', 'death', 'golfer'}\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "print(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "vocab = {'distance','temporary','romeo','fight','self','comedy', 'abide' ,'love', 'persustence' , 'hate', 'world', 'tragedy', 'fool', 'cry', 'hold', 'good', 'dream', 'joy', 'desire', 'sustain', 'arrogance', 'abuse', 'vile', 'asleep', 'warrior', 'perfect', 'death', 'lord', 'heart', 'juliet', 'cry', 'heaven', 'hell'}\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"You know you're in love when you can't fall asleep because reality is finally better than your dreams\"\n",
    "vec = [0 for i in range(len(vocab))]\n",
    "bag = list(vocab)\n",
    "counter = 0\n",
    "for word in test.split():\n",
    "    if word in vocab:\n",
    "        index = bag.index(word)\n",
    "        vec[index] = 1\n",
    "        counter +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
