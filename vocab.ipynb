{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "not_found_words = set()\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('read', 'NN'), ('fell', 'VBD'), ('love', 'VB'), ('way', 'NN'), ('fall', 'NN'), ('asleep', 'VBP'), ('slowly', 'RB')]\n",
      "word:  read | root : read\n",
      "word:  fell | root : fell\n",
      "word:  love | root : love\n",
      "word:  way | root : way\n",
      "word:  fall | root : fall\n",
      "word:  asleep | root : asleep\n",
      "word:  slowly | root : slowly\n",
      "[('loved', 'VBN'), ('yesterday', 'NN'), ('love', 'VB'), ('still', 'RB'), ('always', 'RB'), ('always', 'RB')]\n",
      "word:  loved | root : love\n",
      "word:  yesterday | root : yesterday\n",
      "word:  love | root : love\n",
      "word:  still | root : still\n",
      "word:  always | root : always\n",
      "word:  always | root : always\n",
      "[('saw', 'NN'), ('perfect', 'NN'), ('loved', 'VBD'), ('saw', 'JJ'), ('perfect', 'NN'), ('loved', 'VBD'), ('even', 'RB')]\n",
      "word:  saw | root : saw\n",
      "word:  perfect | root : perfect\n",
      "word:  loved | root : love\n",
      "word:  saw | root : saw\n",
      "word:  perfect | root : perfect\n",
      "word:  loved | root : love\n",
      "word:  even | root : even\n",
      "[('love', 'NN'), ('love', 'NN'), ('made', 'VBD'), ('making', 'VBG'), ('love', 'VB'), ('part', 'NN'), ('bring', 'NN')]\n",
      "word:  love | root : love\n",
      "word:  love | root : love\n",
      "word:  made | root : make\n",
      "word:  making | root : make\n",
      "word:  love | root : love\n",
      "word:  part | root : part\n",
      "word:  bring | root : bring\n",
      "[('thinking', 'VBG'), ('keeps', 'NNS'), ('awake', 'VBP'), ('dreaming', 'VBG'), ('keeps', 'NNS'), ('asleep', 'JJ'), ('keeps', 'NNS'), ('alive', 'JJ')]\n",
      "word:  thinking | root : think\n",
      "word:  keeps | root : keep\n",
      "word:  awake | root : awake\n",
      "word:  dreaming | root : dream\n",
      "word:  keeps | root : keep\n",
      "word:  asleep | root : asleep\n",
      "word:  keeps | root : keep\n",
      "word:  alive | root : alive\n",
      "[('need', 'NN'), ('like', 'IN'), ('heart', 'NN'), ('needs', 'VBZ'), ('beat', 'NN')]\n",
      "word:  need | root : need\n",
      "('like', 'IN')  not found\n",
      "word:  heart | root : heart\n",
      "word:  needs | root : need\n",
      "word:  beat | root : beat\n",
      "[('say', 'VB'), ('love', 'NN'), ('mean', 'NN'), ('love', 'VBP'), ('love', 'NN'), ('mean', 'NN'), ('love', 'IN'), ('bad', 'JJ'), ('days', 'NNS'), ('ahead', 'RB'), ('us', 'PRP'), ('love', 'VB'), ('fight', 'NN'), ('ever', 'RB'), ('love', 'VB'), ('distance', 'NN'), ('us', 'PRP'), ('love', 'VBP'), ('obstacle', 'NN'), ('could', 'MD'), ('try', 'VB'), ('come', 'VB'), ('us', 'PRP'), ('love', 'VB')]\n",
      "word:  say | root : say\n",
      "word:  love | root : love\n",
      "word:  mean | root : mean\n",
      "word:  love | root : love\n",
      "word:  love | root : love\n",
      "word:  mean | root : mean\n",
      "('love', 'IN')  not found\n",
      "word:  bad | root : bad\n",
      "word:  days | root : day\n",
      "word:  ahead | root : ahead\n",
      "('us', 'PRP')  not found\n",
      "word:  love | root : love\n",
      "word:  fight | root : fight\n",
      "word:  ever | root : ever\n",
      "word:  love | root : love\n",
      "word:  distance | root : distance\n",
      "('us', 'PRP')  not found\n",
      "word:  love | root : love\n",
      "word:  obstacle | root : obstacle\n",
      "('could', 'MD')  not found\n",
      "word:  try | root : try\n",
      "word:  come | root : come\n",
      "('us', 'PRP')  not found\n",
      "word:  love | root : love\n",
      "[('know', 'NNS'), ('love', 'VBP')]\n",
      "word:  know | root : know\n",
      "word:  love | root : love\n",
      "[('swear', 'JJ'), ('love', 'NN'), ('right', 'RB'), ('yet', 'RB'), ('know', 'VBP'), ('tomorrow', 'NN')]\n",
      "word:  swear | root : swear\n",
      "word:  love | root : love\n",
      "word:  right | root : right\n",
      "word:  yet | root : yet\n",
      "word:  know | root : know\n",
      "word:  tomorrow | root : tomorrow\n",
      "[('live', 'JJ'), ('hundred', 'VBD'), ('want', 'JJ'), ('live', 'JJ'), ('hundred', 'VBD'), ('minus', 'CC'), ('one', 'CD'), ('day', 'NN'), ('never', 'RB'), ('live', 'VBP'), ('without', 'IN')]\n",
      "word:  live | root : live\n",
      "word:  hundred | root : hundred\n",
      "word:  want | root : want\n",
      "word:  live | root : live\n",
      "word:  hundred | root : hundred\n",
      "('minus', 'CC')  not found\n",
      "('one', 'CD')  not found\n",
      "word:  day | root : day\n",
      "word:  never | root : never\n",
      "word:  live | root : live\n",
      "('without', 'IN')  not found\n",
      "[('today', 'NN'), ('truer', 'VBZ'), ('true', 'JJ'), ('one', 'CD'), ('alive', 'JJ'), ('youer', 'NN')]\n",
      "word:  today | root : today\n",
      "word:  truer | root : truer\n",
      "word:  true | root : true\n",
      "('one', 'CD')  not found\n",
      "word:  alive | root : alive\n",
      "word:  youer | root : youer\n",
      "[('know', 'JJ'), ('world', 'NN'), ('going', 'VBG'), ('crazy', 'JJ'), ('best', 'JJS'), ('rapper', 'JJ'), ('white', 'JJ'), ('guy', 'NN'), ('best', 'JJS'), ('golfer', 'NN'), ('black', 'JJ'), ('guy', 'NN'), ('tallest', 'JJS'), ('guy', 'NN'), ('nba', 'IN'), ('chinese', 'JJ'), ('swiss', 'JJ'), ('hold', 'NN'), ('america', 'JJ'), ('cup', 'NN'), ('france', 'NN'), ('accusing', 'VBG'), ('u', 'JJ'), ('arrogance', 'NN'), ('germany', 'NN'), ('want', 'VBP'), ('go', 'VB'), ('war', 'NN'), ('three', 'CD'), ('powerful', 'JJ'), ('men', 'NNS'), ('america', 'VBP'), ('named', 'VBN'), ('bush', 'NN'), ('dick', 'NN'), ('colin', 'NN'), ('need', 'VBP'), ('say', 'VBP')]\n",
      "word:  know | root : know\n",
      "word:  world | root : world\n",
      "word:  going | root : go\n",
      "word:  crazy | root : crazy\n",
      "word:  best | root : best\n",
      "word:  rapper | root : rapper\n",
      "word:  white | root : white\n",
      "word:  guy | root : guy\n",
      "word:  best | root : best\n",
      "word:  golfer | root : golfer\n",
      "word:  black | root : black\n",
      "word:  guy | root : guy\n",
      "word:  tallest | root : tall\n",
      "word:  guy | root : guy\n",
      "('nba', 'IN')  not found\n",
      "word:  chinese | root : chinese\n",
      "word:  swiss | root : swiss\n",
      "word:  hold | root : hold\n",
      "word:  america | root : america\n",
      "word:  cup | root : cup\n",
      "word:  france | root : france\n",
      "word:  accusing | root : accuse\n",
      "word:  u | root : u\n",
      "word:  arrogance | root : arrogance\n",
      "word:  germany | root : germany\n",
      "word:  want | root : want\n",
      "word:  go | root : go\n",
      "word:  war | root : war\n",
      "('three', 'CD')  not found\n",
      "word:  powerful | root : powerful\n",
      "word:  men | root : men\n",
      "word:  america | root : america\n",
      "word:  named | root : name\n",
      "word:  bush | root : bush\n",
      "word:  dick | root : dick\n",
      "word:  colin | root : colin\n",
      "word:  need | root : need\n",
      "word:  say | root : say\n",
      "[('believe', 'VB'), ('nothing', 'NN'), ('hear', 'JJ'), ('one', 'CD'), ('half', 'NN'), ('see', 'NN')]\n",
      "word:  believe | root : believe\n",
      "word:  nothing | root : nothing\n",
      "word:  hear | root : hear\n",
      "('one', 'CD')  not found\n",
      "word:  half | root : half\n",
      "word:  see | root : see\n",
      "[('lord', 'NN'), ('fools', 'VBZ'), ('mortals', 'NNS')]\n",
      "word:  lord | root : lord\n",
      "word:  fools | root : fool\n",
      "word:  mortals | root : mortal\n",
      "[('world', 'NN'), ('tragedy', 'NN'), ('feel', 'VBP'), ('comedy', 'NN'), ('think', 'VBP')]\n",
      "word:  world | root : world\n",
      "word:  tragedy | root : tragedy\n",
      "word:  feel | root : feel\n",
      "word:  comedy | root : comedy\n",
      "word:  think | root : think\n",
      "[('life', 'NN'), ('comedy', 'NN'), ('think', 'VBP'), ('tragedy', 'NN'), ('feel', 'NN')]\n",
      "word:  life | root : life\n",
      "word:  comedy | root : comedy\n",
      "word:  think | root : think\n",
      "word:  tragedy | root : tragedy\n",
      "word:  feel | root : feel\n",
      "[('thin', 'JJ'), ('line', 'NN'), ('separates', 'NNS'), ('laughter', 'RBR'), ('pain', 'VBP'), ('comedy', 'JJ'), ('tragedy', 'NN'), ('humor', 'NN'), ('hurt', 'VBD')]\n",
      "word:  thin | root : thin\n",
      "word:  line | root : line\n",
      "word:  separates | root : separate\n",
      "word:  laughter | root : laughter\n",
      "word:  pain | root : pain\n",
      "word:  comedy | root : comedy\n",
      "word:  tragedy | root : tragedy\n",
      "word:  humor | root : humor\n",
      "word:  hurt | root : hurt\n",
      "[('self', 'NN'), ('important', 'JJ'), ('everybody', 'NN'), ('going', 'VBG'), ('save', 'JJ'), ('something', 'NN'), ('save', 'VB'), ('trees', 'NNS'), ('save', 'VBP'), ('bees', 'NNS'), ('save', 'VBP'), ('whales', 'NNS'), ('save', 'VBP'), ('snails', 'NNS')]\n",
      "word:  self | root : self\n",
      "word:  important | root : important\n",
      "word:  everybody | root : everybody\n",
      "word:  going | root : go\n",
      "word:  save | root : save\n",
      "word:  something | root : something\n",
      "word:  save | root : save\n",
      "word:  trees | root : tree\n",
      "word:  save | root : save\n",
      "word:  bees | root : bee\n",
      "word:  save | root : save\n",
      "word:  whales | root : whale\n",
      "word:  save | root : save\n",
      "word:  snails | root : snail\n",
      "[]\n",
      "[('thankfully', 'RB'), ('persistence', 'NN'), ('great', 'JJ'), ('substitute', 'NN'), ('talent', 'NN')]\n",
      "word:  thankfully | root : thankfully\n",
      "word:  persistence | root : persistence\n",
      "word:  great | root : great\n",
      "word:  substitute | root : substitute\n",
      "word:  talent | root : talent\n",
      "[('lot', 'NN'), ('cared', 'VBD'), ('enough', 'RB')]\n",
      "word:  lot | root : lot\n",
      "word:  cared | root : care\n",
      "word:  enough | root : enough\n",
      "[('two', 'CD'), ('tragedies', 'NNS'), ('life', 'NN'), ('one', 'CD'), ('lose', 'JJ'), ('heart', 'NN'), ('desire', 'NN'), ('gain', 'NN')]\n",
      "('two', 'CD')  not found\n",
      "word:  tragedies | root : tragedy\n",
      "word:  life | root : life\n",
      "('one', 'CD')  not found\n",
      "word:  lose | root : lose\n",
      "word:  heart | root : heart\n",
      "word:  desire | root : desire\n",
      "word:  gain | root : gain\n",
      "[('world', 'NN'), ('tragedy', 'NN'), ('feel', 'VBP'), ('comedy', 'NN'), ('think', 'VBP')]\n",
      "word:  world | root : world\n",
      "word:  tragedy | root : tragedy\n",
      "word:  feel | root : feel\n",
      "word:  comedy | root : comedy\n",
      "word:  think | root : think\n",
      "[('never', 'RB'), ('story', 'NN'), ('woe', 'NN'), ('juliet', 'JJ'), ('romeo', 'NN')]\n",
      "word:  never | root : never\n",
      "word:  story | root : story\n",
      "word:  woe | root : woe\n",
      "word:  juliet | root : juliet\n",
      "word:  romeo | root : romeo\n",
      "[('life', 'NN'), ('comedy', 'NN'), ('think', 'VBP'), ('tragedy', 'NN'), ('feel', 'NN')]\n",
      "word:  life | root : life\n",
      "word:  comedy | root : comedy\n",
      "word:  think | root : think\n",
      "word:  tragedy | root : tragedy\n",
      "word:  feel | root : feel\n",
      "[('weeping', 'VBG'), ('thing', 'NN'), ('crying', 'VBG'), ('takes', 'VBZ'), ('whole', 'JJ'), ('body', 'NN'), ('weep', 'JJ'), ('feel', 'NN'), ('like', 'IN'), ('bones', 'NNS'), ('left', 'VBD'), ('hold', 'NN')]\n",
      "word:  weeping | root : weep\n",
      "word:  thing | root : thing\n",
      "word:  crying | root : cry\n",
      "word:  takes | root : take\n",
      "word:  whole | root : whole\n",
      "word:  body | root : body\n",
      "word:  weep | root : weep\n",
      "word:  feel | root : feel\n",
      "('like', 'IN')  not found\n",
      "word:  bones | root : bone\n",
      "word:  left | root : leave\n",
      "word:  hold | root : hold\n",
      "[('thin', 'JJ'), ('line', 'NN'), ('separates', 'NNS'), ('laughter', 'RBR'), ('pain', 'VBP'), ('comedy', 'JJ'), ('tragedy', 'NN'), ('humor', 'NN'), ('hurt', 'VBD')]\n",
      "word:  thin | root : thin\n",
      "word:  line | root : line\n",
      "word:  separates | root : separate\n",
      "word:  laughter | root : laughter\n",
      "word:  pain | root : pain\n",
      "word:  comedy | root : comedy\n",
      "word:  tragedy | root : tragedy\n",
      "word:  humor | root : humor\n",
      "word:  hurt | root : hurt\n",
      "[('single', 'JJ'), ('death', 'NN'), ('tragedy', 'NN'), ('million', 'CD'), ('deaths', 'NNS'), ('statistic', 'JJ')]\n",
      "word:  single | root : single\n",
      "word:  death | root : death\n",
      "word:  tragedy | root : tragedy\n",
      "('million', 'CD')  not found\n",
      "word:  deaths | root : death\n",
      "word:  statistic | root : statistic\n",
      "[('go', 'VB'), ('go', 'VB')]\n",
      "word:  go | root : go\n",
      "word:  go | root : go\n",
      "[('irish', 'JJ'), ('abiding', 'VBG'), ('sense', 'NN'), ('tragedy', 'NN'), ('sustained', 'VBD'), ('temporary', 'JJ'), ('periods', 'NNS'), ('joy', 'NN')]\n",
      "word:  irish | root : irish\n",
      "word:  abiding | root : abide\n",
      "word:  sense | root : sense\n",
      "word:  tragedy | root : tragedy\n",
      "word:  sustained | root : sustain\n",
      "word:  temporary | root : temporary\n",
      "word:  periods | root : period\n",
      "word:  joy | root : joy\n"
     ]
    }
   ],
   "source": [
    "def addToVocab(filename):\n",
    "    global counter\n",
    "    f = open(filename,\"r\")\n",
    "    for line in f:\n",
    "        line = line.lower()\n",
    "        sent = re.sub('[\\W_]+', ' ', line)\n",
    "        wordsList = nltk.word_tokenize(sent)\n",
    "        wordsList = [w for w in wordsList if not w in stop_words]\n",
    "        tagged = nltk.pos_tag(wordsList)\n",
    "        print(tagged)\n",
    "        for word in tagged:\n",
    "            try:\n",
    "                tag = get_wordnet_pos(word[1])\n",
    "                if tag != None :\n",
    "                    final_word =  lemmatizer.lemmatize(word[0], pos = tag )\n",
    "                    print(\"word: \", word[0], \"| root :\",final_word)\n",
    "                    vocab.add( final_word)\n",
    "                else:\n",
    "                    print(word, \" not found\")\n",
    "                    not_found_words.add(word)\n",
    "                    counter +=1\n",
    "            except:\n",
    "                print(word, \" not found\")\n",
    "                not_found_words.add(word)\n",
    "                counter +=1\n",
    "        # print(tagged)\n",
    "    f.close()\n",
    "\n",
    "addToVocab(\"love-quotes.txt\")\n",
    "addToVocab(\"comedy-quotes.txt\")\n",
    "addToVocab(\"tragedy-quotes.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('ought', 'MD'), ('pro', 'FW'), ('two', 'CD'), ('gon', 'FW'), ('viva', 'FW'), ('behind', 'IN'), ('oh', 'UH'), ('accept', 'IN'), ('minus', 'CC'), ('600', 'CD'), ('warrior', 'WRB'), ('towards', 'IN'), ('1973', 'CD'), ('us', 'PRP'), ('1400', 'CD'), ('abuse', 'IN'), ('love', 'FW'), ('nba', 'IN'), ('whoever', 'WDT'), ('love', 'IN'), ('three', 'CD'), ('like', 'IN'), ('800', 'CD'), ('side', 'FW'), ('zen', 'CD'), ('every', 'DT'), ('absorbs', 'IN'), ('de', 'IN'), ('toward', 'IN'), ('nine', 'CD'), ('vile', 'IN'), ('broken', 'IN'), ('5', 'CD'), ('within', 'IN'), ('onto', 'IN'), ('around', 'IN'), ('might', 'MD'), ('braver', 'IN'), ('laugh', 'IN'), ('mancha', 'FW'), ('boys', 'IN'), ('whosoever', 'WDT'), ('plus', 'CC'), ('la', 'FW'), ('na', 'IN'), ('whore', 'IN'), ('without', 'IN'), ('whatever', 'WDT'), ('unless', 'IN'), ('neither', 'DT'), ('vie', 'FW'), ('whenever', 'WRB'), ('900', 'CD'), ('alike', 'IN'), ('may', 'MD'), ('whose', 'WP$'), ('allow', 'IN'), ('past', 'IN'), ('deeper', 'IN'), ('rachel', 'FW'), ('upon', 'IN'), ('although', 'IN'), ('trough', 'IN'), ('another', 'DT'), ('inside', 'IN'), ('worth', 'IN'), ('surfer', 'FW'), ('could', 'MD'), ('outta', 'IN'), ('beyond', 'IN'), ('six', 'CD'), ('beside', 'IN'), ('2', 'CD'), ('except', 'IN'), ('need', 'MD'), ('million', 'CD'), ('would', 'MD'), ('five', 'CD'), ('along', 'IN'), ('whether', 'IN'), ('must', 'MD'), ('na', 'TO'), ('thousand', 'CD'), ('one', 'CD'), ('since', 'IN'), ('verb', 'IN'), ('2000', 'CD'), ('ghost', 'FW'), ('though', 'IN'), ('either', 'CC'), ('four', 'CD')}\n",
      "1570\n",
      "339\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "print(not_found_words)\n",
    "print(len(vocab))\n",
    "print(counter)\n",
    "print(len(not_found_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test and add field\n",
    "\"us\" in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('warrior')\n",
    "vocab.add('abuse')\n",
    "vocab.add('vile')\n",
    "vocab.add('hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"You know you're in love when you can't fall asleep because reality is finally better than your dreams\"\n",
    "vec = [0 for i in range(len(vocab))]\n",
    "bag = list(vocab)\n",
    "counter = 0\n",
    "for word in test.split():\n",
    "    if word in vocab:\n",
    "        index = bag.index(word)\n",
    "        vec[index] = 1\n",
    "        counter +=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
